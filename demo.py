import torch
from transformers import BertTokenizer, BertForSequenceClassification
import gradio as gr

# DÃ©tection du device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Chargement du tokenizer et du modÃ¨le fine-tunÃ©
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model = BertForSequenceClassification.from_pretrained("/content/results/checkpoint-15958")
model.to(device)
model.eval()

# Fonction de prÃ©diction
def predict_toxicity(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=128, padding=True)
    inputs = {key: val.to(device) for key, val in inputs.items()}
    
    with torch.no_grad():
        outputs = model(**inputs)
    
    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
    toxic_prob = probs[0][1].item()
    label = "ðŸŸ¥ TOXIC" if toxic_prob > 0.5 else "ðŸŸ© NON-TOXIC"
    return f"{label} (probabilitÃ© : {toxic_prob:.2f})"

# Interface Gradio
interface = gr.Interface(
    fn=predict_toxicity,
    inputs=gr.Textbox(lines=2, placeholder="Entrez votre phrase ici...", label="Commentaire"),
    outputs=gr.Text(label="RÃ©sultat"),
    title="DÃ©tection de ToxicitÃ©",
    allow_flagging="never",
    live=False
)

if __name__ == "__main__":
    interface.launch()
